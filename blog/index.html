<!doctype html><html lang=en-gb><head><title>The Bigger Picture Blog | Matt Copperwaite</title><meta charset=utf-8><meta name=language content="en"><meta name=description content><meta name=keywords content><meta name=viewport content="width=device-width,initial-scale=1"><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><link rel="shortcut icon" type=image/png href=/favicon.ico><link type=text/css rel=stylesheet href=/css/posts.min.9d00414be708b07c685f180cfce5239fac4e85078a970260044342d7422f18f8.css integrity="sha256-nQBBS+cIsHxoXxgM/OUjn6xOhQeKlwJgBENC10IvGPg="><link type=text/css rel=stylesheet href=/css/custom.min.c7d0618bf3996aafcc1b82eb3ddfb053c4c06ca40ecfab6006545026401023c8.css integrity="sha256-x9Bhi/OZaq/MG4LrPd+wU8TAbKQOz6tgBlRQJkAQI8g="><link rel=alternate type=application/rss+xml+xml href=https://matt.copperwaite.net/blog/rss.xml title="Matt Copperwaite"><script type=application/ld+json>{"@context":"http://schema.org","@type":"WebSite","url":"https:\/\/matt.copperwaite.net\/blog\/","name":"The Bigger Picture Blog","author":{"@type":"Person","name":""},"description":""}</script></head><body><div class=burger__container><div class=burger aria-controls=navigation aria-label=Menu><div class="burger__meat burger__meat--1"></div><div class="burger__meat burger__meat--2"></div><div class="burger__meat burger__meat--3"></div></div></div><nav class=nav id=navigation><ul class=nav__list><li><a href=/>Home</a></li><li><a class=active href=/blog/>Blog</a></li><li><a href=/showcase/>Showcase</a></li><li><a href=/about-me/>About Me</a></li></ul></nav><main><div class=post-list__container><div><h1>The Bigger Picture Blog</h1><ul class=post-list><li class=post><article class=post__header><header class=post__header><h2 class=post__title><a href=/blog/providing-useful-security-advice/>Providing Useful Security Advice</a></h2></header><time class=post__date datetime="2021-10-29 18:10:32 +0100 +0100">Oct 29 2021</time><p>I know I certainly dread that message:</p><blockquote><p>You have a massive security issues by the way</p></blockquote><p>It instantly puts you on the defensive, and in my experience, it&rsquo;s also not true.</p><p>On top of that the phrasing creates an information asymmetry and puts you in a position you have to defend. You may in reality be in a strong position, but by starting off with a non-collaborative discussion it can be difficult to identify the true problem.</p><p><a href=./armchair-security-experts>As I mentioned twice in my previous post</a> security is all about context, and I wanted to expand on that point. You may, in isolation, have something in your environment that isn&rsquo;t ideal. We all do. The alternative is to have no service at all. But IT security is entirely about risks and trade-offs.</p><p>It may well be that you do have an issue here, and it may also be that you have managed it already through another control such as alerts that warn when that scenario happens, but to an outsider it is often difficult to draw the relationship between a risk and a control.</p><p>Let&rsquo;s turn it around. Say you discover an issue in someone else&rsquo;s service and you want to draw their attention to it. What would be the best way to broach that subject? It needs to be collaborative and resolves the issue. This question appears a lot in interviews in this industry, in one form or another, but I&rsquo;ve yet to see a response I&rsquo;m entirely happy with. Let&rsquo;s expand on it then.</p><p>First off, setting the scenario. I&rsquo;m excluding where you are an outsider as bug bounty programmes are <a href=https://en.wikipedia.org/wiki/Bug_bounty_program>well established and documented</a>.</p><p>In this scenario you are a Security Architect, Engineer or similar in a business. You have access to the source code. You also have access to the person who is responsible for the code, and that you&rsquo;re using modern delivery methodologies.</p><p>As mentioned, the first issue you have is that perhaps the issue you&rsquo;ve found has already been risk managed. To account for this the first step is to check the documentation. There is a chance that the issue you are seeing has been documented but difficult to find. Unless you&rsquo;re somewhere that employs enough people and pays well enough to attract good people it&rsquo;s unlikely this is documented at all, but let&rsquo;s try to minimise wasting someone else&rsquo;s time first. Time they could spend resolving other issues.</p><p>In general terms you&rsquo;re trying to identify if the issue you are seeing is actually an issue and test your assumptions.</p><p>In the more likely scenario that the documentation doesn&rsquo;t exist, hard to find, or have the information you need. Next is to approach the person responsible. I think it&rsquo;s important to coach your wording appropriately. Never make assumptions about the issue you have found. You want to look like you are coming from the position of being wrong or were not able to find the right information. You are now attempting to find the right information. Phrase it something like:</p><blockquote><p>I was looking at your code and I&rsquo;m trying to identify if something I&rsquo;m seeing is actually an issue.</p></blockquote><p>Followed by explaining the issue.</p><p>There&rsquo;s no point saying there is a massive security issues because, as mentioned, you put the other person on the defensive, and it may well be that you are wrong. You are reducing your chances that they will pay attention to you in the future, when perhaps there is a genuine issue.</p><p>You may discover at this point that they have identified the issue, mitigated it, and the documentation is good, but not something that can be found quickly. At this point you may want to suggest making it easier to find the documentation and your job is done.</p><p>However, if they have mitigated the issue but they haven&rsquo;t documented well, or they haven&rsquo;t mitigated it at all then you have some work to do.</p><p>This is your opportunity to create some security credit and I recommend you take it. This will make working on issues in future much easier.</p><p>The first step is to offer to raise a ticket for the work. This means that it has a greater chance of the issue being worked on. If you&rsquo;re unfamiliar with the project this is also the point to clarify where they record their issues so you know it&rsquo;s somewhere they will see it.</p><p>Ideally the next step is to be proactive, although it&rsquo;s not always practical.</p><p>If it&rsquo;s a documentation issue then offer to update their documents.</p><p>It also may well be a genuine unmitigated issue, and much the same way with the documentation, if you&rsquo;re comfortable you should then be proactive in fixing the problem. Raising a Pull Request for the change and adding or updating tests.</p><p>That way the team with the issue are more likely to listen to you and fix the problem next time, which is the ultimate goal: reducing the risk of disruption to your system.</p></article></li><li class=post><article class=post__header><header class=post__header><h2 class=post__title><a href=/blog/armchair-security-experts/>Armchair Security Experts</a></h2></header><time class=post__date datetime="2021-10-28 10:30:32 +0100 +0100">Oct 28 2021</time><p>Providing security advice to someone can be very difficult, particularly when unsolicited. This is because IT security is entirely context based. I use the term <em>Armchair Security Experts</em> to describe people who provide security advice, often wrong, as if they had expertise in the subject area.</p><p>Wikipedia explains the term Armchair Expert (or <a href=https://en.wikipedia.org/wiki/Armchair_theorizing>Armchair Theorizing</a>) well enough, and the security aspect is much the same. Someone with limited practical expertise in the field. Or more generously, someone whose responsibilities doesn&rsquo;t include owning any risk.</p><p>Security is all about context. If you make broad bold statements about security without leaving your armchair to consider the context you are providing negative value to a delivery.</p><p>The security advice Armchair Security Experts sometimes provide I call these Security Grenades. This would often be in the middle of a big important meeting and someone semi senior would throw in something like &ldquo;I have heard that S3 is insecure&rdquo;. This is so bafflingly bad information that it de-rails the purpose of the meeting.</p><p>This is closely related to the <a href=https://en.wikipedia.org/wiki/Dead_cat_strategy>dead cat strategy</a> (which is more or less as horrible as it sounds) but instead of drawing attention away from a dangerous line of discussion it diverts the delivery team in to trying to handle this knowledge asymmetry.</p><p>This is where in an Agile delivery that taking all stakeholders on the journey with you is so important.</p><p>You need to keep everyone informed and up to date on your progress, your assumptions, and your solutions. You should be able to identify those who have the power to derail your project and put the extra effort in to keeping them informed so that they don&rsquo;t scupper your delivery at the final stages.</p></article></li><li class=post><article class=post__header><header class=post__header><h2 class=post__title><a href=/blog/behavioural-economics-second-order-thinking/>Behavioural Economics and Second Order Thinking</a></h2></header><time class=post__date datetime="2021-10-27 18:10:32 +0100 +0100">Oct 27 2021</time><p>I really enjoyed the <a href=https://fs.blog/2020/03/chestertons-fence/>article on Chesterton&rsquo;s Fence</a> I came across recently. It really made me reflect on <a href=https://en.wikipedia.org/wiki/Behavioral_economics>Behavioural Economics</a> again &ndash; as does so much stuff I read.</p><p>The Chesterton&rsquo;s Fence analogy is an excellent description of why challenging assumptions in Agile processes is so important, but the reason I like it is because thinking in a Behavioural Economics way you can use it to inform Second Order Thinking. Or in some ways, start to predict the future about what effects a particular action has.</p><p>In Behavioural Economics terms, the fence can have multiple purposes, but what it incentives is keeping something in or out. By removing that fence is no-longer performs that function and whatever protection it afforded no-longer is true.</p><p>I know in reality however I&rsquo;m sure I would mindlessly be attempting to remove the fence post without thinking about it&rsquo;s purpose. Fortunately because of the repeatability of DevOps practices we can re-enforce that thinking each time.</p><p>I write this however, not so much attempting to be a sooth sayer, but, much like the fence, as a warning that what Second Order Thinking and Behavioural Economics can tell you about the future, is still assumptions based on assumptions, and that you can really only understand what happens next through small fail fast experimentation.</p><p>So perhaps the answer the true analogy isn&rsquo;t about the fence being moved, but instead about making assumptions about the effect of moving it.</p><p>But then there is such a thing as taking an analogy too far.</p></article></li><li class=post><article class=post__header><header class=post__header><h2 class=post__title><a href=/blog/public-wifi-vs-personal-vpns/>Is Public Wi-Fi More Secure Than Personal VPN Services?</a></h2></header><time class=post__date datetime="2021-08-22 18:10:32 +0100 +0100">Aug 22 2021</time><p>An IT security group I associate with recently wrote a blog post on <a href=https://joelgsamuel.medium.com/how-to-keep-your-smartphone-safe-from-spying-d7d50fbed817>threats and scenarios for securing mobile phones</a>. It&rsquo;s well worth a read.</p><p>One line stood out to me as interesting because I wanted to understand the evidence for that. It <em>feels</em> true, but that&rsquo;s not the same as <em>being</em> true.</p><p>That Greg is&mldr;</p><blockquote><p>more likely to select a malicious VPN provider than he is to run into malicious Wi-Fi</p></blockquote><p>Speaking to the authors the answer was more anecdotal than quantifiable based upon the lack of reports on malicious public Wi-Fi in recent years and the number of reports of malicious personal VPN providers.</p><p>To validate that there are <a href=https://www.theregister.com/2020/07/17/ufo_vpn_database/>plenty of examples</a> of personal VPN services leaking logs, but as I have written about before <a href=https://matt.copperwaite.net/blog/assessing-security-practices-of-3rd-party-projects/>that doesn&rsquo;t make those services more, or indeed less, secure than they are now</a>.</p><p>Also, while public VPN services are not a new concept, they have <a href="https://trends.google.co.uk/trends/explore?date=all&geo=GB&q=%2Fg%2F11gfj_yxtn,%2Fg%2F11hbgq8gct,%2Fg%2F11b7y71slf">become more prominent in the last 5-6 years</a>, which could lead you to think that data leaks by personal VPN services are more likely because those services are note-worthy and therefore more interesting to report on.</p><p>Conversely using public Wi-Fi has been <a href=https://www.theregister.com/2007/08/02/public_wifi_hack/>a concern for many people for far longer</a> but with phone 3G and up being more common place this would mean its usage is likely lower. It seems though that evidence for this and &lsquo;hacks&rsquo; on public WiFi service having significant effects in the real world are hard to track down. The reasons for this are either because it rarely happens, or rarely gets identified.</p><h2 id=defining-terms>Defining Terms<a class=anchor href=#defining-terms>#</a></h2><p>For clarity a <em>public <a href=https://en.wikipedia.org/wiki/Wi-Fi>WiFi</a> service</em> is any wireless network with an internet connection provided by a company in a public space. This means coffee shops such as <a href=https://wifi.starbucks.com/>Starbucks</a> but does not include corporate Guest WiFi that you might find in a workplace. A <em>public WiFi provider</em> is the company that provides that WiFi service.</p><p>Whereas personal VPN services are a kind of internet service provider that supplies internet access via a <a href=https://en.wikipedia.org/wiki/Virtual_private_network>Virtual Private Network</a> and is aimed <a href=https://en.wikipedia.org/wiki/Direct-to-consumer>directly at consumers rather than businesses</a>. A personal VPN provider is a company such as NordVPN or ExpressVPN that run these services.</p><h2 id=comparisons>Comparisons<a class=anchor href=#comparisons>#</a></h2><p>The core of the question here is:</p><blockquote><p>Are you more likely to use a public WiFi that has a vulnerability that could do you harm, than a personal VPN service that has a vulnerability that could do you harm?</p></blockquote><p>Part of the complexity in answering this is that we&rsquo;re comparing apples and oranges. You can tell through a logic test, that you can run a VPN over public Wi-Fi but not the other way around. This dissimilarity makes comparing risks difficult and the only reasonable way to measure it is through qualitative thought experiments.</p><h3 id=economic-incentives-for-security>Economic Incentives for Security<a class=anchor href=#economic-incentives-for-security>#</a></h3><p>To start with lets look at the reasons a company might run one of these services as the economic models for public WiFi services and personal VPN services are quite different. Using Behavioural Economics we can identify constraints and motivations for running it.</p><p>Personal VPN services have a very traditional &ldquo;quid pro quo&rdquo; subscription model, this means that those who tout their services as improving security have a specific interest in you having secure system, or they would be out of business. It doesn&rsquo;t mean it won&rsquo;t happen, but they are incentivised to make it less subseptable to vulnerabilities, in much the same way cloud providers are.</p><p>The payment model for public WiFi services is more complex. Coffee shops and libraries are widely regarded as a place to get free WiFi. The payment model is indirect. In coffee shops you are paying for your WiFi as a portion of your purchases. The WiFi encourages you to choose that venue over other similar venues, and the act of you staying there means you spend more on food and drink. You can infer therefore, that a coffee shop or library is more interested in providing a public WiFi service at the lowest cost they can entice people with. It&rsquo;s not going to harm their business as much if there&rsquo;s malware flying around the network &ndash; although arguably it should.</p><h3 id=security-considerations>Security Considerations<a class=anchor href=#security-considerations>#</a></h3><p>I wanted to address some of the good, although patchy and inconsistent work that personal VPN providers do on security of their services. WiFi providers, as mentioned, don&rsquo;t have the same incentives to provide this information.</p><p><a href=https://www.pcmag.com/news/what-does-a-vpn-security-audit-really-prove>Some personal VPN services do bring in auditors for their code</a>, which is good as long as you trust the audit, but also comes with the caveat that the audit covers the code for a particular point in time. <a href="https://hackerone.com/nordsecurity?type=team">Some also have vulnerability reporting incentives</a>. While some can <a href=https://nordvpn.com/features/cybersec/>provide additional blocking</a>.</p><p>A thing to consider is that personal VPN services typically requires you to download and install potentially untrustworthy applications on to your machine to gain access to their services. While <a href=https://nordvpn.com/ovpn/>some provide configurations for widely used VPN software</a>.</p><h3 id=discoverability>Discoverability<a class=anchor href=#discoverability>#</a></h3><p>The final part is discoverability. This is your likelihood of accessing a personal VPN service vs a public WiFi service.</p><p>A personal VPN service would typically be a one-to-one relationship between consumer and business. Where as there are a lot of public WiFi providers. In the United Kingdom public WiFi services are usually from big telecoms providers such as <a href=https://tfl.gov.uk/campaign/station-wifi>Virgin Media</a>, <a href=https://www.btwifi.co.uk/>BT</a> and <a href=https://www.sky.com/wifi>Sky</a>, but they could also in a smaller shops be an ad-hoc PSK posted on a wall, or printed on a menu. You may use several in a year (or used to). However a personal VPN service can be accessed from anywhere at any time.</p><p>I think it&rsquo;s also a likely scenario that if you were new to personal VPN services you would probably <a href=https://www.techradar.com/uk/vpn/best-vpn>perform a search for the best providers</a> which is really a list of affiliate links and the one at the top probably gives the author the largest share of the referral fee, but you might not choose the top one because they&rsquo;re the most expensive, so maybe the 5th one? Then at some point down the road that company isn&rsquo;t doing so well and gets bought out by someone not so reputable, and <a href=https://en.wikipedia.org/wiki/Escalation_of_commitment>sunk cost fallacy</a> says you&rsquo;re going to stick with it anyway.</p><h2 id=moot-points>Moot Points<a class=anchor href=#moot-points>#</a></h2><p>There are some security considerations that both public WiFi services and personal VPN services share. It&rsquo;s worth drawing those out here as some may see them as one providing an advantage of one over another.</p><h3 id=https>HTTPS<a class=anchor href=#https>#</a></h3><p>The <a href=https://blogs.vmware.com/networkvirtualization/2020/09/network-security-encrypted.html/>vast majority of web traffic is now HTTPS</a> which means you are less likely to have your traffic changed in some way, but it is still likely that the providers can see meta data about your traffic. Typically you provide a public WiFi provider some information about you on sign-up, although I rarely see that being verified. A personal VPN provider can probably tell who was accessing what because you&rsquo;ve presumably provided them some payment details, although I&rsquo;m sure some more privacy minded folks might pay via a crypto currency.</p><h3 id=further-monetisation>Further Monetisation<a class=anchor href=#further-monetisation>#</a></h3><p>I have no doubt that large public WiFi providers monetise your traffic by taking meta data and selling that on. While some VPN providers claim they don&rsquo;t, if you&rsquo;re looking to make cost savings and choosing a cheaper provider I wouldn&rsquo;t count on them changing their minds.</p><h3 id=data-leaks>Data Leaks<a class=anchor href=#data-leaks>#</a></h3><p>Both <a href=https://www.bbc.co.uk/news/technology-51682280>public WiFi services</a> and <a href=https://www.teiss.co.uk/free-vpn-apps-leaked-personal-data/>personal VPN services</a> have leaked personal data in the past. It&rsquo;s an inevitability of time. It&rsquo;s the nature of IT, as mentioned though I don&rsquo;t think it&rsquo;s necessarily a reflection of the current IT practices of those services.</p><h2 id=conclusion>Conclusion<a class=anchor href=#conclusion>#</a></h2><p>Like most answers in IT security, it really depends on your circumstances. <a href=https://youtu.be/WVDQEoe6ZWY>Tom Scott does (like always) provide a fantastic summary of why you might want to use a VPN</a> and I completely agree, while <a href=https://www.troyhunt.com/im-partnering-with-nord-as-a-strategic-adviser/>Troy Hunt has a less than unbiased view on why you should use NordVPN</a>.</p><p>What this demonstrates is that VPNs are not a quick fix, even for technically minded people. There are a lot of ways to get it wrong.</p><p>That means if you&rsquo;re in a position to use a personal VPN services, given the amount of choices you may choose one that doesn&rsquo;t meet all your security needs. Whereas public WiFi services are less frequently used and have a larger surface area, and where they are most used they are run by large reputable companies.</p><p>So it seems like public WiFi services are probably less malicious than some or all of the personal VPN services, but a huge aspect of that is exposure.</p></article></li><li class=post><article class=post__header><header class=post__header><h2 class=post__title><a href=/blog/the-future-of-yaml/>YAML: Out of Order</a></h2></header><time class=post__date datetime="2021-07-28 18:10:32 +0100 +0100">Jul 28 2021</time><p>I did enjoy <a href=https://drewdevault.com/2021/07/28/The-next-YAML.html>Drew DeVault&rsquo;s wish-list for the future of YAML today</a>. I have to agree with all of it. YAML is terrigood.</p><p>I recall reading an article years ago (that I can&rsquo;t find now) comparing the YAML spec to other similar languages such as XML, JSON, etc, and whatever you pick YAML&rsquo;s spec surpasses any of them in terms of length. The implication being that YAML is particularly difficult to implement correctly.</p><p>But YAML is also great, and I think that is down to the syntax being highly intuitive. It&rsquo;s familiar to a lot of people, and in particular those familiar with Python.</p><p>One thing I think Drew over-looked though, and I&rsquo;m sure there are others like Drew who would not automatically recognise this, is one really important aspect of YAML, and is why languages like TOML won&rsquo;t replace every case of YAML, is the inference of sequencing in a YAML file.</p><p>This becomes particularly apparent with Ansible. You cannot have an Ansible playbook without sequencing, they have a top down order to the structure. You will also find this in most CI languages such as GitLab CI and GitHub Actions &ndash; although they are less apparent because you can also break the sequence by referring to other steps.</p><p>This inferred sequencing is not something you can do in TOML. Much like in CI pipelines you could reference other steps, but it starts to act much like <code>GOTO 10</code> as well as increasing the cognitive load on the reader to find all the steps across a file or set of files.</p><p>Terraform is another good comparison, HCL doesn&rsquo;t enforce a sequence, each block in most cases references another. You then end up creating potentially complex graphs in your parser to identify what needs to be the first to run, and what needs to be run after that.</p><p>Again, I do not disagree with Draw&rsquo;s assessment, but I do think we also have to recognise that the sequencing is an important part of what makes YAML so accessible, and if we&rsquo;re looking to the future of YAML this is a feature that needs to be retained.</p></article></li><li class=post><article class=post__header><header class=post__header><h2 class=post__title><a href=/blog/your-lack-of-planning-is-not-my-emegency/>Your Lack of Planning is Not My Emergency</a></h2></header><time class=post__date datetime="2021-07-27 18:10:32 +0100 +0100">Jul 27 2021</time><p>Recently a colleague shared a rule he uses when dealing with urgent requests:</p><blockquote><p>Your lack of planning is not my emergency</p></blockquote><p>My gut instinct was to disagree with it, but I couldn&rsquo;t articulate it properly at the time. Now I see how it&rsquo;s a regressive solution, which always makes me think there has to be a better way, and I wanted to explain my reasoning.</p><p>The history of it comes from working in IT where often capabilities need to be updated in a hurry, but the task has a dependency on another team, your team, who does not own that change. Your team now has a bunch of pressure exerted on it because another team encountered something that they hadn&rsquo;t planned for.</p><p>The rule is a way to quickly diffuse any expectation that because another team made a mistake, that your team is responsible for fixing it. This is because these events are toxic in nature causing extra pressure to your own deliveries.You could also reasonably assume if your team helped out, the team who owned the event won&rsquo;t learn anything and will know to go direct to you in future. A single urgent request in isolation is fine, but happening regularly can be crippling to a team.</p><p>Although if this kind of task ends up requiring an urgent response from your team, to dismiss it outright you will be making assumptions. The following is a breakdown of those assumptions.</p><h2 id=lack-of-planning>Lack of Planning<a class=anchor href=#lack-of-planning>#</a></h2><p>How often in IT are rapid changes caused by a lack of planning? I&rsquo;m betting in most cases the source of the tasks are incidents, or security patches. If you dismiss the request, you will be seen as unwilling to help out at a time of need, and as someone who may be unwilling to participate in similar future requests.</p><p>I would expect this also means you reduce your chances of being consulted in future, or those who are making changes don&rsquo;t know to inform you of them because you are not considered on the normal path to release.</p><h2 id=emergency-exit>Emergency Exit<a class=anchor href=#emergency-exit>#</a></h2><p>The other assumption to check is, how much of an emergency is it? Most of the project managers I&rsquo;ve worked with would often say &ldquo;Can you do this by tomorrow?&rdquo; and when you trace back to the engineering team they&rsquo;re happy with it being the next day, or May, or whenever. You may have decided not to participate based on faulty data.</p><p>Often the delivery date has been made up based on guess-work and have no meaning. I always like to check the deadlines. They rarely hold true.</p><h2 id=the-user-factor>The User Factor<a class=anchor href=#the-user-factor>#</a></h2><p>Another consideration is that users are often the cause of these rush jobs. Set aside that telling them &lsquo;no&rsquo; is a path to shadow IT, but it might be an indicator that your process isn&rsquo;t fast enough for the demands for the business. If you have users who need software installed today and your SLA is 5 days, then maybe your SLAs are at fault.</p><h2 id=happy-to-help>Happy to Help<a class=anchor href=#happy-to-help>#</a></h2><p>You should always be willing to improve the operational effectiveness of your business. To do that you have to participate. That is the cost of being an effective team. Perhaps a single team is often the source of the problems, so where are their problems stemming from? Are they performing an incident post-mortem? Or learning any lessons? Is there something you can do with them to prevent their issues re-arising? Perhaps this is the true problem.</p><p>Finally, if you haven&rsquo;t planned extra capacity in to your work, then have you actually planned your own work properly?</p></article></li><li class=post><article class=post__header><header class=post__header><h2 class=post__title><a href=/blog/running-good-one-to-ones/>Running Effective One-to-Ones</a></h2></header><time class=post__date datetime="2021-06-14 18:10:32 +0100 +0100">Jun 14 2021</time><p>I&rsquo;ve run one-to-ones for a couple years now I realised I didn&rsquo;t have a good plan for how to run them effectively, and weirdly there didn&rsquo;t seem to be a lot of discussion written up about them that I could find online.</p><p>I spoke with some colleagues who pointed to the <a href=https://www.manager-tools.com/manager-tools-basics>Manager Tools Basics podcast</a> which has a set of episodes totalling around 90 minutes on the subject at hand. They are however seemingly recorded in 2005 which makes them over 15 years old. This lines up with the banner at the of the webpage. While this does seem old and despite pandemics and changes in technology it seems to hold up for the most part. The issue though is that for one, they are very verbose and second, the information isn&rsquo;t replicated online.</p><p>What I wanted to do here is to pull out what I found the most important so that others can run their own effective one-to-ones without having to dedicate 90 minutes to listen to a podcast. This is a condensed view of what to do. If you want the complete explanation of why you do this I would recommend listening to the podcast itself.</p><p>In the podcast they refer to the person who works for you as your &ldquo;direct&rdquo;. I don&rsquo;t really like the term, but I can&rsquo;t think of a better one, so I&rsquo;m going to re-use it.</p><h2 id=where-and-when>Where and when<a class=anchor href=#where-and-when>#</a></h2><ul><li>Run your one-to-ones weekly. As the manager put it in your and the directs calendar. You can move it, but don&rsquo;t miss it.</li><li>No more than 30 minutes. An hour is too long.</li><li>Run it in space where the direct feels comfortable</li></ul><h2 id=what-to-discuss-agenda>What to discuss (Agenda)<a class=anchor href=#what-to-discuss-agenda>#</a></h2><ul><li>Your directs views: 10 minutes</li><li>Your views: 10 minutes</li><li>The future: 10 minutes</li></ul><p>Don&rsquo;t rigidly stick to the agenda. If your direct wants to spend more time talking about their views then that&rsquo;s their prerogative. This is their meeting.</p><p>Your views might be about how interactions in the team are working, or not. The future is about where they are heading. Are they looking to move on? Or stay?</p><p>An important note is that you, as a manager, should have a broad opening question. In the podcast they suggest &ldquo;How&rsquo;s it going?&rdquo;.</p><h2 id=review>Review<a class=anchor href=#review>#</a></h2><p>I disagree somewhat with this agenda. It seems to lean towards on the manager&rsquo;s view. The important thing is that your directs have a voice and you understand their wants and needs. If they want to talk for the entire time that&rsquo;s up to them. It&rsquo;s a two way street anyway and an opportunity for coaching.</p><p>I personally would avoid the Joey Tribbiani comparison and possibly ask &ldquo;How are things?&rdquo; but has roughly the same meaning.</p><p>The other thing to note is that as meetings go, one-to-ones are deceptively straight-forward. They work better when you don&rsquo;t over think them. Other than scheduling you almost let your directs run them themselves.</p><p>Other than that I was quite happy to get this insight.</p></article></li><li class=post><article class=post__header><header class=post__header><h2 class=post__title><a href=/blog/engineers-care-less-about-the-os/>Engineers Care Less About The OS</a></h2></header><time class=post__date datetime="2021-04-08 18:10:32 +0100 +0100">Apr 8 2021</time><p><a href=https://www.lastweekinaws.com/blog/>Last Week in AWS</a> is another one of my favourite blogs, but <a href=https://www.lastweekinaws.com/blog/nobody-cares-about-the-operating-system-anymore/>this weeks one titled &lsquo;Nobody Cares About the Operating System Anymore&rsquo;</a> definitely got me thinking.</p><p>If you&rsquo;ve never read Last Week in AWS the thing to note is that scores really high on the snark factor, and like most blogs it tends towards the hyperbolic titles to attract readers and discussion, after all, it&rsquo;s not as pithy, and not going to attract as much attention if the title is &lsquo;In the cloud, Engineers don&rsquo;t really care about the Operating System anymore&rsquo;. Which is probably why my blog is much less snarky, and much more boring.</p><p>However, in this case I think the premise is wrong. It&rsquo;s not that even engineers no-longer really care about what Operating System you choose but that Cloud based Virtual Machines (as a catch all for EC2s, Azure VMs and whatever GCP calls compute) is no-longer used and for me is actually an indicator of &lsquo;infrastructure smell&rsquo;. I.e.: that something is old, or unpatched, or not cloud native. For me, if I have to use a VM in <a href=https://en.wikipedia.org/wiki/Hyperscale_computing>hyperscale cloud</a>, something has gone wrong somewhere.</p><p>There are instances where you might use VMs, or more commonly called VPS, and dedicated boxes, which you find on more commodity providers such as DigitalOcean, Scaleway, or RedStation (to broach the tip of the iceberg), but when you have SaaS, FaaS, and Serverless Docker environments such as Fargate and Kubernetes, I really struggle to see the value in using dedicated, always on, compute. If anything its technical debt that you need to monitor, maintain, patch and scale.</p><p>As a side note, yes you <a href=https://chemidy.medium.com/create-the-smallest-and-secured-golang-docker-image-based-on-scratch-4752223b7324>sometimes</a> have to choose a base Linux distribution for Docker images, but this is essentially a game of pick your preferred package manager, and then it&rsquo;s done and you never ever change that <code>FROM</code> value except to update the version number.</p><p>I can see why Corey would interpret that as nobody cares about the Operating System, but the broader picture to me is not that the Operating System doesn&rsquo;t matter, it&rsquo;s that we&rsquo;re at a point in technology in hyperscale cloud that the technologies allow us to abstract away VMs, making the variety of choice of Operating System is less relevant, but it&rsquo;s the cloud providers abstraction layers that enable that, rather than engineers not caring.</p></article></li><li class=post><article class=post__header><header class=post__header><h2 class=post__title><a href=/blog/chaos-engineering-your-team/>Chaos Engineering Your Team</a></h2></header><time class=post__date datetime="2020-12-09 18:10:32 +0100 +0100">Dec 9 2020</time><p>Mountain Goat Software runs possibly one of my favourite blogs at the moment. This recent post <a href=https://www.mountaingoatsoftware.com/blog/should-your-team-adopt-no-meeting-weeks>&ldquo;Should Your Team Adopt No-Meeting Weeks&rdquo; really resonated with me</a>.</p><p>I read an article while back, but of course I cannot find now, about how you might want to consider applying <a href=https://en.wikipedia.org/wiki/Chaos_engineering>Chaos Engineering</a>, not only to your technology, but also your people. A random person gets selected maybe once a week, to take the day off. Simulating a sick-leave like situation.</p><p>I&rsquo;m a huge proponent of the idea that no single person should be critical to your business, and in fact they become a massive risk to your business that is only realised once they leave. It also creates an uncollaborative working environment because you will have a lot of different pressures from different people on one person. This is covered a lot in <a href=https://www.amazon.co.uk/Phoenix-Project-DevOps-Helping-Business-ebook/dp/B00AZRBLHO>The Phoenix Project</a>.</p><p>Using the principles behind Chaos Engineering you can build in expectations in to your team that you should be able to survive the loss of a person.</p><p>What I like with the experiment mentioned in the post, taking a random person out of meetings, was that this it is similar to Chaos Engineering your team, but at a smaller scale. In the situation where the person, who is critical to your meeting, gets unceremoniously booted out of said meeting, you have identified a process that doesn&rsquo;t account for the loss of one person.</p><p>The other issue is that if people learn they&rsquo;re not necessary for a meeting they stop coming, which I assume is the intention. However now, you start kicking out important people from the meeting, such as the executive authoriser who was there specifically for that meeting.</p><p>In the post these issues was explained as the experiment failing. I would look at it from the other direction, it&rsquo;s a failing of the processes to have a dependency in a single person.</p><p>As CGP Grey often says, <a href=https://youtu.be/boezS4C_MFc>one is none</a>.</p><p>Now don&rsquo;t get me wrong, I&rsquo;m not saying you need two (or more) executives in the meeting. I&rsquo;m taking the broader picture. Does everyone really need to be in the same room at the same time? In my experience I would say 90% of the time the answer is no.</p><p>Instead the major discussions should happen before the meeting, on your preferred collaboration tool. Any reading material can be distributed before hand and consumed at your leisure. If someone has a vested interest, such as an executive authoriser, they can raise any concerns before anyone steps in the room.</p><p>The meeting becomes a formality to say &ldquo;a decision needs to be made by this date and time&rdquo;. It&rsquo;s more like that cliche moment in weddings in movies where the vicar says &ldquo;Speak now or forever hold your peace&rdquo;. The meeting should be 5 minutes tops.</p><p>The only other time people might want to meet at the same time is if something was being presented, such as a town hall or a sprint review. In those situations you should ensure that those meetings are recorded and published so that others can view and ask questions later if they were interested, but weren&rsquo;t able to attend.</p><p>This leaves everyone free to work on what&rsquo;s important, when it&rsquo;s important. Not spending their entire day in meetings being presented material they could have accessed at any time. Or using time less efficiently because they&rsquo;re winding up to a meeting.</p><p>But, as the original post admits, this may only work in a Google-eque business process utopia.</p></article></li><li class=post><article class=post__header><header class=post__header><h2 class=post__title><a href=/blog/common-sense-as-bad-practice/>Common Sense as Bad Practice</a></h2></header><time class=post__date datetime="2020-11-25 13:35:32 +0100 +0100">Nov 25 2020</time><p>It came to me in conversation recently as to how toxic &ldquo;Common Sense&rdquo; is.</p><p>Common Sense says &ldquo;well, everyone uses X, so we should use X&rdquo; or &ldquo;Everyone should know this.&rdquo;</p><p>But those are fallacies and assumptions that aren&rsquo;t tested or rooted in evidence.</p><p>Usually Common Sense comes from asking your mates or colleagues, or assuming they think the same as you. However, by doing that you inherit bias in those assumptions. You make decisions that don&rsquo;t hold true, and at best you are likely going to make poor decisions, and at worst create an exclusionary environment &ndash; locking out people who you will want to include.</p><p>If you believe it is Common Sense, prove it is Common Sense. Test it out. Trial it, and properly. Don&rsquo;t be part of the problem.</p><p>Also, challenge &ldquo;Common Sense&rdquo; when it is used.</p><blockquote><p>Why is it common sense?</p></blockquote><blockquote><p>Who else thinks they know that as the answer?</p></blockquote><p>You should end up with a better solution that is more open and equitable than your assumptions.</p></article></li><li class=post><article class=post__header><header class=post__header><h2 class=post__title><a href=/blog/assessing-security-practices-of-3rd-party-projects/>Assessing Security Practices of 3rd Party products</a></h2></header><time class=post__date datetime="2020-11-20 18:10:32 +0100 +0100">Nov 20 2020</time><p>In recent months I&rsquo;ve been involved in discussions about whether remote working tools are &ldquo;secure&rdquo; or not. The answer to any blunt question like that is, as always, &ldquo;it depends&rdquo;, but this is as helpful as getting financial advice from YouTube adverts.</p><p>It struck me that a lot of people interested in IT security often judge tools based upon how many vulnerabilities there are in a product. But lets be accurate here, they are judging it on how many security vulnerabilities are reported, or visible.</p><p>Once the pandemic forced us all to work from home, <a href=https://www.bbc.co.uk/news/business-52115434>Zoom seemed to be the target for every &ldquo;white hat&rdquo; hacker consultancy</a> <em>generously</em> giving their time to declare the 0 days they found to news websites, with nothing more in return than their company name to be placed along side the <del>advert</del> article.</p><p>These articles seemingly leading to several instances of &ldquo;Enterprise&rdquo; security teams declaring Zoom as insecure and made attempts to block its usage in their environments.</p><p>But is Zoom unsecure? And does blocking it improve things?</p><p>If you block Zoom, what will people use instead? Google Hangout? Skype? Chime? WebEx? Some random tool they found on the internet? Is blocking Zoom making things more or less secure?</p><p>Zoom got the attention because its user base and visibility increased massively during the pandemic. Admittedly it did have some low hanging fruit, but was it more or less of a threat to a business than your employees using something like <a href=https://en.wikipedia.org/wiki/Omegle>Omegle</a> for work?</p><p>If we used the same metrics in which we judge Zoom and apply it to Windows or Linux those security teams would block almost all operating systems out there except maybe OpenBSD and BeOS.</p><h2 id=it-security-shouldnt-be-reactionary>IT security shouldn&rsquo;t be reactionary<a class=anchor href=#it-security-shouldnt-be-reactionary>#</a></h2><p>IT security needs to be evidence lead. Would you say now that Zoom, after 6 months of global usage it is not secure? Other than the occasional <a href=https://twitter.com/mvanhulten/status/1329885925862760450>person posting their Zoom codes</a>, which is the Video Conferencing equivalent of calling your S3 bucket <code>big-bank-data</code>.</p><p>So can how can we be less reactionary in future?</p><p>One thing is to <a href=https://www.theregister.com/2020/04/03/zoom_security_improvements/>recognise that Zoom fixed a lot</a>, if not all, the issues that the security researchers were making a fuss over. Usually within days or weeks.</p><p>Where-as shouldn&rsquo;t we <a href=https://www.zdnet.com/article/google-to-github-times-up-this-unfixed-high-severity-security-bug-affects-developers/>trust GitHub less</a> for having a long standing issue it&rsquo;s been unable or unwilling to fix?</p><p>What I&rsquo;m proposing is instead of making decisions based upon what we read in the tech news this week, we measure good security practice from 3rd parties on how quickly and responsibly vulnerabilities in their products are announced and fixed, and be pragmatic about what your users need and expect from their IT.</p></article></li></ul><ul class=tags__list></ul></div></div></main><script src=/js/index.min.49e4d8a384357d9b445b87371863419937ede9fa77737522ffb633073aebfa44.js integrity="sha256-SeTYo4Q1fZtEW4c3GGNBmTft6fp3c3Ui/7YzBzrr+kQ=" crossorigin=anonymous></script></body></html>